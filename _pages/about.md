---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a fourth-year Ph.D. student in the statistics department at the University of Michigan, where I am advised by [Prof. Ambuj Tewari](https://ambujtewari.github.io/). Previously, I studied mathematics and computer science at the University of Mississippi (Olemiss). During my time there, I was fortunate to work with [Prof. Rizwanur Khan](http://home.olemiss.edu/~rrkhan/) and [Prof. Micah Milinovich](http://home.olemiss.edu/~mbmilino/) in number theory. 


Research Interest
======

I am broadly interested in the theory of machine learning. My topics of interest include learning theory, online learning, adversarial robustness, vector-valued prediction, operator learning, and partial-feedback models, dynamical systems. In the past, I have also worked on probabilistic number theory. 

Preprints
======
- [On the Benefits of Active Data Collection in Operator Learning](https://arxiv.org/abs/2410.19725)    
  with Ambuj Tewari  
  Preprint, 2024
  
- [Error Bounds for Learning Fourier Linear Operators](https://arxiv.org/pdf/2408.09004)    
  with Ambuj Tewari  
  Preprint, 2024


- [The Complexity of Sequential Prediction in Dynamical Systems](https://arxiv.org/abs/2402.06614)    
  with Vinod Raman, Ambuj Tewari  
  Preprint, 2024


- [A Combinatorial Characterization of Supervised Online Learnability](https://arxiv.org/abs/2307.03816)   
  with Vinod Raman, Ambuj Tewari   
  Preprint, 2023



Publications 
======


  - [A Characterization of Multioutput Learnability](https://arxiv.org/abs/2301.02729)   
    with Vinod Raman, Ambuj Tewari    
    *Journal of Machine Learning Research (JMLR)*, 2024   


 - [Multiclass Transductive Online Learning]()   
   with Steve Hanneke, Amirreza Shaeiri, Vinod Raman    
   <font color='blue'> Spotlight at </font> *Conference on Neural Information Processing Systems (NeurIPS)*, 2024  

 - [Smoothed Online Classification can be Harder than Batch Classification](https://arxiv.org/pdf/2405.15424)   
   with Vinod Raman, Ambuj Tewari         
   *Conference on Neural Information Processing Systems (NeurIPS)*, 2024  

 - [Online Learning with Set-Valued Feedback](https://arxiv.org/abs/2306.06247)   
   with Vinod Raman, Ambuj Tewari         
   *Conference on Learning Theory (COLT)*, 2024

- [Apple Tasting: Combinatorial Dimensions and Minimax Rates](https://arxiv.org/abs/2310.19064)    
  with Vinod Raman, Ananth Raman, Ambuj Tewari  
  *Conference on Learning Theory (COLT)*, 2024

- [Online Infinite-Dimensional Regression: Learning Linear Operators](https://arxiv.org/abs/2309.06548)       
 with Vinod Raman, Ambuj Tewari  
  *Conference on Algorithmic Learning Theory (ALT)*, 2024

- [Multiclass Online Learnability under Bandit Feedback](https://arxiv.org/abs/2308.04620)   
  with Ananth Raman, Vinod Raman, Idan Mehalel, Ambuj Tewari   
  *Conference on Algorithmic Learning Theory (ALT)*, 2024

- [On the Learnability of Multilabel Ranking](https://arxiv.org/abs/2304.03337)   
  with Vinod Raman, Ambuj Tewari    
  *<font color='blue'> Spotlight at </font> Conference on Neural Information Processing Systems (NeurIPS)*, 2023  

- [On Proper Learnability between Average- and Worst-case Robustness](https://arxiv.org/abs/2211.05656)    
  with Vinod Raman, Ambuj Tewari   
  *Conference on Neural Information Processing Systems (NeurIPS)*, 2023   

- [Multiclass Online Learning and Uniform Convergence](https://proceedings.mlr.press/v195/hanneke23b.html)    
  with Steve Hanneke, Shay Moran, Vinod Raman, Ambuj Tewari     
  *Conference on Learning Theory (COLT)*, 2023  

- [A Weighted Version of Erdős-Kac Theorem](https://www.sciencedirect.com/science/article/abs/pii/S0022314X21003681)  
 with Rizwanur Khan, Micah Milinovich  
*Journal of Number Theory*, 2022    
  

- [A Conjectural Asymptotic Formula for Multiplicative Chaos in Number Theory](https://link.springer.com/article/10.1007/s40993-022-00332-x)    
 with Daksh Aggarwal, William Verreault, Asif Zaman, Chengui Zheng      
*Research in Number Theory*, 2022   


- [Sums of Random Multiplicative Functions over Function Fields with Few Irreducible Factors](https://www.cambridge.org/core/journals/mathematical-proceedings-of-the-cambridge-philosophical-society/article/abs/sums-of-random-multiplicative-functions-over-function-fields-with-few-irreducible-factors/636667B07830029AB35196FF595CA055)   
 with Daksh Aggarwal, William Verreault, Asif Zaman, Chengui Zheng      
*Mathematical Proceedings of the Cambridge Philosophical Society*, 2022   

- [A Weighted Version of Erdős-Kac Theorem](https://egrove.olemiss.edu/cgi/viewcontent.cgi?article=2687&context=hon_thesis)  
  *Undergraduate Thesis*




Talks
======
- Online Learning with Set-Valued Feedback (Signal Processing Seminar UM EECS, 2024)
- Online Infinite-Dimensional Regression: Learning Linear Operators (MSSISS, 2024)
- Online Infinite-Dimensional Regression: Learning Linear Operators (ALT 2024)
- A Weighted Version of Erdos-Kac Theorem (Number Theory Seminar, Ole Miss) 
- Computational Investigations of Random Multiplicative Functions (Fields Institute, 2020)


Miscellaneous Writing
======

- [An Elementary Evaluation of $\zeta(2n)$ Using Dirichlet's Kernel](https://unique-subedi.github.io/Misc_Writings/Dirichlet_s_Kernel_and_Zeta_2n_.pdf)    
  Micah B. Milinovich and Unique Subedi
- [On $L_1$-norm of Dirichlet's Kernel](https://unique-subedi.github.io/Misc_Writings/L1_Norm_of_Dirichlet_s_Kernel.pdf)  
  Micah B. Milinovich and Unique Subedi




Teaching
======
I have been a Graduate Student Instructor for the following courses at Michigan:
- Probability and Distribution Theory, Fall 2023
- [Statistics and AI, aka Deep Learning](https://ambujtewari.github.io/stats315-winter2023/), Winter 2023
- [Bayesian Data Analysis](https://yixinwang.github.io/courses/bayesian/fall22/bayesian22f.html), Fall 2022
- Applied Regression Analysis, Winter 2022
- Introduction to Statistics and Data Analysis, (Fall 2021 & Winter 2024)
